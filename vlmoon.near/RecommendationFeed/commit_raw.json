{"tx_hash": "42rkrRoFxq9jDgXbtbG983r9gRZpZGYqsWkTdeB9UyTm", "action_id_social": "EkM8zxoSPfvEpXi45PQBUJ8DQWy6DmvYiSzYoBCGf2Fv-0-widget", "block_id": 100739962, "block_timestamp": "2023-09-09T13:59:24.137Z", "signer_id": "vlmoon.near", "widget_name": "RecommendationFeed", "source_code": "function isSupportTensorflow() {\r\n  try {\r\n    const X_testTensor = tf.tensor2d([\r\n      [0, 0, 0, 0, 0, 0, 0],\r\n      [0, 0, 0, 0, 0, 0, 0],\r\n      [0, 0, 0, 0, 0, 0, 0],\r\n    ]);\r\n\r\n    return (\r\n      <h4>\r\n        Your version of the Near VM support that Version of the recomendation\r\n        system\r\n      </h4>\r\n    );\r\n  } catch (e) {\r\n    return (\r\n      <h4>\r\n        Your version of the Near VM dont support that Version of the\r\n        recomendation system\r\n      </h4>\r\n    );\r\n  }\r\n}\r\n\r\nfunction getFeedByAccountIdQuery(accountId, limit, offset) {\r\n  if (!limit) {\r\n    limit = 15;\r\n  }\r\n  if (!offset) {\r\n    offset = 0;\r\n  }\r\n  const whereClause = accountId\r\n    ? `where: { account_id: { _eq: \"${accountId}\" } }`\r\n    : \"\";\r\n  const indexerQuery = `\r\n      query GetFeedByAccountId {\r\n          dataplatform_near_social_feed_posts(order_by: { block_height: desc }, limit: ${limit}, offset: ${offset} ${whereClause}) {\r\n              id\r\n              account_id\r\n              block_timestamp\r\n              content\r\n              comments {\r\n                  account_id\r\n                  block_height\r\n              }\r\n              post_likes {\r\n                  account_id\r\n                  block_height\r\n              }\r\n          }\r\n      }\r\n    `;\r\n  return indexerQuery;\r\n}\r\n\r\nfunction getAllPostQuery(limit, offset) {\r\n  if (!limit) {\r\n    limit = 15;\r\n  }\r\n  if (!offset) {\r\n    offset = 0;\r\n  }\r\n\r\n  const indexerQuery = `\r\n      query GetAllPostQuery {\r\n          dataplatform_near_social_feed_posts(order_by: { block_height: desc }, limit: ${limit}, offset: ${offset}) {\r\n              id\r\n              account_id\r\n              block_timestamp\r\n              content\r\n              comments {\r\n                  account_id\r\n                  block_height\r\n              }\r\n              post_likes {\r\n                  account_id\r\n                  block_height\r\n              }\r\n          }\r\n      }\r\n    `;\r\n  return indexerQuery;\r\n}\r\n\r\nfunction getFollowingsById(accountId) {\r\n  const url = \"https://api.near.social/index\";\r\n  const headers = { \"Content-Type\": \"application/json\" };\r\n\r\n  const payload = {\r\n    action: \"graph\",\r\n    key: \"follow\",\r\n    options: {\r\n      order: \"desc\",\r\n      accountId: accountId,\r\n    },\r\n  };\r\n\r\n  const response = fetch(url, {\r\n    method: \"POST\",\r\n    headers: headers,\r\n    body: JSON.stringify(payload),\r\n  });\r\n  const accountIds = response.body.map((item) => item.value.accountId);\r\n  return accountIds ?? [\"no data\"];\r\n}\r\n\r\nfunction fetchFollowingsRecursive(\r\n  accountId,\r\n  depth,\r\n  visited,\r\n  interested_account_ids\r\n) {\r\n  if (!interested_account_ids) {\r\n    interested_account_ids = [];\r\n  }\r\n\r\n  if (!visited) {\r\n    visited = new Set();\r\n  }\r\n\r\n  if (depth <= 0 || visited.has(accountId)) {\r\n    return [];\r\n  }\r\n\r\n  // Fetch followings of the current account\r\n  console.log(`accountId ${accountId}`);\r\n  let followings;\r\n  try {\r\n    followings = getFollowingsById(accountId).slice(0, 30);\r\n  } catch (e) {\r\n    console.log(`Error ${JSON.stringify(e)}`);\r\n    followings = [];\r\n  }\r\n\r\n  // Add the current account to the visited set\r\n  visited.add(accountId);\r\n\r\n  // Recursively fetch followings of followings\r\n  const followingLists = followings.map((following) => {\r\n    if (!visited.has(following)) {\r\n      const followingFollowings = fetchFollowingsRecursive(\r\n        following,\r\n        depth - 1,\r\n        visited\r\n      );\r\n      return [following, ...followingFollowings];\r\n    }\r\n    return [];\r\n  });\r\n\r\n  // Flatten and filter the lists of followings, removing duplicates\r\n  const allFollowings = followingLists.flat().filter((following) => {\r\n    return (\r\n      !visited.has(following) && !interested_account_ids.includes(following)\r\n    );\r\n  });\r\n\r\n  return allFollowings;\r\n}\r\n\r\nfunction fetchPostsRecursive(accountId, depth, limit, offset) {\r\n  if (depth === 0) {\r\n    return [];\r\n  }\r\n\r\n  // // Fetch and extract posts for the current account\r\n\r\n  const operationsDoc = getFeedByAccountIdQuery(accountId, limit, offset);\r\n  const operationName = \"GetFeedByAccountId\";\r\n  const response = fetchGraphQL(operationsDoc, operationName, {});\r\n\r\n  if (!response) {\r\n    response.body.data.dataplatform_near_social_feed_posts = [];\r\n  }\r\n\r\n  const postsData = response.body.data.dataplatform_near_social_feed_posts;\r\n  // const postEntries = [];\r\n  const postEntries = Array.isArray(postsData)\r\n    ? postsData.map((post) => ({\r\n        id: post.id,\r\n        account_id: post.account_id,\r\n        block_timestamp: post.block_timestamp,\r\n        content: post.content,\r\n        comments: Array.isArray(post.comments)\r\n          ? post.comments.map((comment) => comment.account_id)\r\n          : [],\r\n        post_likes: Array.isArray(post.post_likes)\r\n          ? post.post_likes.map((like) => like.account_id)\r\n          : [],\r\n      }))\r\n    : [];\r\n\r\n  // Fetch followings of the current account\r\n  const followings = getFollowingsById(accountId);\r\n\r\n  // Recursively fetch posts from followings of followings\r\n  let posts = [...postEntries];\r\n  for (const following of followings) {\r\n    const followingPosts = fetchPostsRecursive(\r\n      following,\r\n      depth - 1,\r\n      limit,\r\n      offset\r\n    );\r\n    posts = posts.concat(followingPosts);\r\n  }\r\n\r\n  return posts;\r\n}\r\n\r\nfunction mapPostToFeatures(post, followings, targetId) {\r\n  const engagement_score = calculateEngagementScore(post, followings);\r\n  const target_id_like = post.post_likes.includes(targetId) ? 20 : 0;\r\n  const target_id_comment = post.comments.includes(targetId) ? 20 : 0;\r\n\r\n  const followerEngagements = followings.map((followerId) => {\r\n    const followerEngagement = calculateEngagementScore(post, [followerId]);\r\n    return followerEngagement;\r\n  });\r\n\r\n  const totalFollowerEngagement = followerEngagements.reduce(\r\n    (sum, engagement) => sum + engagement,\r\n    0\r\n  );\r\n  const avg_engagement_followers =\r\n    followings.length > 0 ? totalFollowerEngagement / followings.length : 0;\r\n\r\n  return {\r\n    engagement_score,\r\n    avg_engagement_followers,\r\n    target_id_like,\r\n    target_id_comment,\r\n  };\r\n}\r\n\r\nfunction calculateEngagementScore(post, followings) {\r\n  const { comments, post_likes } = post;\r\n  let engagement_score = 0;\r\n\r\n  followings.forEach((followerId) => {\r\n    if (post_likes.includes(followerId)) {\r\n      engagement_score += 2; // Increment engagement score for likes\r\n    }\r\n\r\n    if (comments.includes(followerId)) {\r\n      engagement_score += 2; // Increment engagement score for comments\r\n    }\r\n  });\r\n\r\n  return engagement_score;\r\n}\r\n\r\nconst GRAPHQL_ENDPOINT =\r\n  props.GRAPHQL_ENDPOINT ||\r\n  \"https://queryapi-hasura-graphql-24ktefolwq-ew.a.run.app\";\r\n\r\nState.init({\r\n  feeds: [\"no feed\"],\r\n  modelWasLoaded: \"no\",\r\n});\r\n\r\nfunction fetchGraphQL(operationsDoc, operationName, variables) {\r\n  return fetch(`${GRAPHQL_ENDPOINT}/v1/graphql`, {\r\n    method: \"POST\",\r\n    headers: { \"x-hasura-role\": \"dataplatform_near\" },\r\n    body: JSON.stringify({\r\n      query: operationsDoc,\r\n      variables: variables,\r\n      operationName: operationName,\r\n    }),\r\n  });\r\n}\r\n\r\nfunction loadModel() {\r\n  tf.loadModel(\r\n    \"recomendation\",\r\n    `https://recommendation-system-near-social.onrender.com/models/${context.accountId}/model.json`\r\n  ).then((res) => {\r\n    console.log(\"Model was loaded\");\r\n    State.update({\r\n      modelWasLoaded: \"yes\",\r\n    });\r\n  });\r\n}\r\n\r\nfunction predictTest() {\r\n  //Step 1 - +\r\n  const posts = fetchGraphQL(\r\n    getAllPostQuery(500, 0),\r\n    queryName,\r\n    {}\r\n  ).body.data.dataplatform_near_social_feed_posts.map((post) => ({\r\n    id: post.id,\r\n    account_id: post.account_id,\r\n    block_timestamp: post.block_timestamp,\r\n    content: post.content,\r\n    comments: post.comments.map((comment) => comment.account_id),\r\n    post_likes: post.post_likes.map((like) => like.account_id),\r\n  }));\r\n\r\n  //Step 2\r\n  const followings = fetchFollowingsRecursive(context.accountId, 2);\r\n\r\n  console.log(`Followings ${JSON.stringify(followings)}`);\r\n\r\n  // // Map posts to features\r\n  const postsWithFeatures = posts.map((post) =>\r\n    mapPostToFeatures(post, followings, context.accountId)\r\n  );\r\n\r\n  // Extract features for prediction\r\n  const featuresForPrediction = postsWithFeatures.map((post) => [\r\n    post.engagement_score,\r\n    post.avg_engagement_followers,\r\n    post.target_id_like,\r\n    post.target_id_comment,\r\n  ]);\r\n\r\n  const X_testTensor = tf.tensor2d(featuresForPrediction);\r\n\r\n  tf.predict(\"recomendation\", X_testTensor).then((result) => {\r\n    const predictionArray = Object.entries(result).map(([index, value]) => ({\r\n      index: Number(index),\r\n      value,\r\n    }));\r\n\r\n    predictionArray.sort((a, b) => b.value - a.value);\r\n\r\n    const topN = 100;\r\n    const topPredictions = predictionArray.slice(0, topN);\r\n\r\n    // Filter allPosts based on top predictions\r\n    const filteredPosts = topPredictions.map(\r\n      (prediction) => posts[prediction.index]\r\n    );\r\n\r\n    State.update({\r\n      feeds: [...filteredPosts],\r\n    });\r\n  });\r\n}\r\n\r\nconst renderData = (a) => {\r\n  return <div key={JSON.stringify(a)}>{JSON.stringify(a)}</div>;\r\n};\r\n\r\nconst renderedData = state.feeds.map(renderData);\r\n\r\nreturn (\r\n  <>\r\n    {isSupportTensorflow()}\r\n    <h2>Hackathon Report</h2>\r\n    <div>\r\n      First of all I want to say thanks to the Near Team and Sponsors for making\r\n      this event happens, you are did a good job.\r\n    </div>\r\n    <h2>Setup</h2>\r\n    <div>\r\n      In order to run this code, you must clone the viewer -\r\n      https://github.com/NearSocial/viewer And in this project in package.json\r\n      file set up the Social VM dependency\r\n      <p>\r\n        \"near-social-vm\":\r\n        \"git+https://github.com/vlmoon99/VM.git#add-tensorflow-api\"\r\n      </p>\r\n      I kindly request that we limit the use of the 'vlmoon.near' account for\r\n      feed predictions. Given that I'm currently running a free Node.js server,\r\n      the process of training and saving new models can be resource-intensive\r\n      for this server. I recommend running your own local server and utilizing\r\n      tools like ngrok for testing purposes with your specific account IDs\r\n    </div>\r\n    <h2>My Story</h2>\r\n    <div>\r\n      When I decided to choose the topic of a Recommendation System for the\r\n      hackathon, I understood that it wouldn't be a simple task for me. To make\r\n      this idea a reality, I had to dive into various aspects. Initially, I\r\n      considered a basic approach, where I would calculate a post's score based\r\n      on the involvement of followers and the followers of followers. However,\r\n      it became apparent that this approach wasn't suitable because we all have\r\n      unique preferences. A one-size-fits-all algorithm wouldn't suffice. Given\r\n      my background in Machine Learning and AI, I began researching how I could\r\n      tackle this problem using these algorithms. I found that many\r\n      recommendation systems rely on large vector databases and a single model\r\n      that predicts recommendations based on user actions and those of their\r\n      connections. While this is effective in traditional web projects (Web\r\n      2.0), it isn't ideal for Web 3.0, where decentralization and user control\r\n      over data are paramount. To address this, I aimed to create a system that\r\n      could work on the client-side, avoiding the need for a heavyweight\r\n      server-side model. However, this approach presented its own set of\r\n      challenges. Distributing training and prediction functions across\r\n      different machines can yield inconsistent results. To mitigate this, I\r\n      decided to create a separate server responsible for training the model and\r\n      saving it. Clients would fetch the model and execute predictions. This\r\n      server-based approach was adopted to simplify development and deployment.\r\n      While this approach is a step towards decentralization, it still comes\r\n      with trade-offs. Decentralization often requires sacrificing some aspects\r\n      of performance, usability, and accuracy for the sake of data privacy. As I\r\n      began implementing this idea, I encountered several challenges. One major\r\n      hurdle was understanding how to run a TensorFlow (TF) model inside a\r\n      virtual machine (VM). I partially resolved this issue, but it involved a\r\n      somewhat brute force approach. In future versions of the VM, I hope to see\r\n      standardized methods for extending widget functionality and handling\r\n      dependencies. Another challenge was determining the exact algorithm to use\r\n      for creating a lightweight, fast, and client-executable model. My current\r\n      algorithm involves precalculating certain data before making predictions,\r\n      such as user involvement. To achieve my vision of a lightweight\r\n      recommendation system, I've identified two key challenges to address:\r\n      enabling the VM to work seamlessly with TensorFlow JS and developing a\r\n      machine learning algorithm for client-side prediction. This approach may\r\n      involve a combination of supervised learning and reinforcement learning.\r\n      In conclusion, I'd like to express my gratitude to the creators of Near\r\n      Social and all other developers who have contributed to this platform.\r\n      It's a fantastic, innovative idea, and I believe it represents the future\r\n      of Web 3.0. I'm eager to continue improving this platform by adding more\r\n      functionality to the VM and implementing my ideas. I'd also welcome\r\n      collaboration or advice from others who share this vision and want to help\r\n      make it a reality. Together, we can turn this dream into a practical\r\n      solution.\r\n    </div>\r\n    <h4>Github of edited VM verison</h4>\r\n    <p>\r\n      https://github.com/vlmoon99/VM/commit/23b8d083166c702dc4e4af7afe1880275de07292#diff-4255535b3b5add42e1263cb0dc4529cd5c802aed92a979e507d39648e3bb335e\r\n    </p>\r\n    <h4>\r\n      Github of the Backend (Simple backend for train the tf model and send it\r\n      to the client)\r\n    </h4>\r\n    <p>https://github.com/vlmoon99/recommendation_system_near_social_backend</p>\r\n    <button onClick={loadModel}>Click to load</button>\r\n    <h1>TF Model Loaded status {state.modelWasLoaded}</h1>\r\n    <button onClick={predictTest}>Click to predict</button>\r\n    <div>FEEDS : {renderedData}</div>\r\n  </>\r\n);\r\n", "metadata": null, "branch": null, "widget_modules_used": null, "widget_url": "https://near.social/#/vlmoon.near/widget/RecommendationFeed", "fact_widget_deployments_id": "f2396a2639377e559f1f0b364d0fb751", "inserted_timestamp": "2024-03-07T05:24:05.087Z", "modified_timestamp": "2024-03-07T05:24:05.087Z", "__row_index": 0}